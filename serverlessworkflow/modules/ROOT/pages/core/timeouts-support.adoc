= Timeouts on events for {context}
:compat-mode!:
// Metadata:
:description: Using timeouts in {context}
:keywords: kogito, workflow, serverless, timeout, timer, expiration

When defining a state in a workflow you can set a timeout which is a property used to control the maximum time this state should take to be complete. In case of the time is elapsed and overdue, this state is considered timed-out, and the workflow moves to the next stated defined in the transition. The properties that you can use when defining a state timeout are described in the link:{spec_doc_url}#event-timeout-definition[Serverless Workflow specification].

The event-based states can define a property `eventTimeout` which uses ISO 8601 data and time format to specify a duration of time, for instance, you can if you can represent 15 minutes like `PT15M`,  to represent 15 minutes or 2 days, 3 hours and 4 minutes `P2DT3H4M`.

[NOTE]
====
Event timeouts can not be defined as a specific point in time, but it should be an amount of time, a duration, which is considered to start when the referred state becomes active in the workflow.
====

[IMPORTANT]
====
{product_name} currently, supports timeout only for *Callback* and *Switch* states with events, other states are going to support timeouts in the future releases.
====

=== Callback state timeout
Callback state can be used when you need to publish an event to trigger an external service and waits an asynchronous response as an event, the callback. Once this event is consumed, the workflow continues the execution to the next state defined in the transition property. See more on xref:eventing/working-with-callbacks.adoc[Callback state in {context}].

Since the callback event halts the execution util the event is consumed, you can define an `eventTimeout` for it, and in case the event does not arrive in the defined duration time, the workflow continues the execution moving to the next state defined in the transition, see the <<callback-state, example>>.

[#callback-state]
.Example of callback state with timeout
[source,json]
----
{
 "name": "CallbackState",
 "type": "callback",
 "action": {
   "name": "callbackAction",
   "functionRef": {
     "refName": "callbackFunction",
     "arguments": {
       "input": "${\"callback-state-timeouts: \" + $WORKFLOW.instanceId + \" has executed the callbackFunction.\"}"
     }
   }
 },
 "eventRef": "callbackEvent",
 "transition": "CheckEventArrival",
 "onErrors": [
   {
     "errorRef": "callbackError",
     "transition": "FinalizeWithError"
   }
 ],
 "timeouts": {
   "eventTimeout": "PT30S"
 }
}
----

=== Switch state timeout

Switch states can be defined with link:{spec_doc_url}#switch-state-event-conditions[eventConditions] property, where the workflow execution waits to make a decision depending on the events to be consumed and matched, defined through link:{spec_doc_url}#event-definition[event definition].

In this situation, you can define an event timeout, that controls the maximum time to wait for an event to match the conditions, if this time is expired, the workflow moves to the state defined in the `defaultCondition` property in the switch state, as showed in the <<switch-state, example>>.

See more details about this state on the link:{spec_doc_url}#switch-date[Serverless Workflow specification].

[#switch-state]
.Example of switch state with timeout
[source,json]
----
{
    "name": "ChooseOnEvent",
    "type": "switch",
    "eventConditions": [
    {
        "eventRef": "visaApprovedEvent",
        "transition": "ApprovedVisa"
    },
    {
        "eventRef": "visaDeniedEvent",
        "transition": "DeniedVisa"
    }
    ],
        "defaultCondition": {
        "transition": "HandleNoVisaDecision"
    },
        "timeouts": {
        "eventTimeout": "PT5S"
    }
}
----

=== Deploying a timed-based workflow

n order to deploy a work that contains timeouts or any other timer-based action, it is necessary to have Job Service running in your environment, which is an external service responsible for workflows timers, see the <<job-service, section>> for more information.
In the <<timeout-example, timeout example>> you can see in details how to set up a knative infrastructure with the workflow and job service running.

[#job-service]
=== Job Service configuration

All timer-related actions that might be declared in a workflow, are handled by a supporting service, called Job Service, which is responsible for managing, scheduling, and firing all actions (jobs) to be executed in the workflows.

Suppose the workflow service is not configured to use job service or there is no such service running. In that case, all timer-related actions use an embedded in-memory implementation of job service, which should not be used in production, since when the application shutdown, all timers are lost, which in a serverless architecture is a very common behavior with the scale to zero approach. That said, the no job service configuration can only be used for testing or development, but not for production.

The main goal of the Job Service is to work with only active jobs. The Job Service tracks only the jobs that are scheduled and that need to be executed. When a job reaches a final state, the job is removed from the Job Service. All job information and transition states are sent to the Kogito Data Index Service where they can be indexed and made available for GraphQL queries.

==== Job Service persistence

An important configuration aspect of job service is the persistence mechanism, where all job information is stored in a database that makes this information durable upon service restarts and guarantees no information is lost.

==== PostgreSQL

Using PostgreSQL is the recommended database to be used with job service where it is already configured with Flyway for the schema creation, in this way all tables are created by the service, in case you need to externally control the database schema, you can check the SQL scripts in (link) and apply them.
You need to set the proper configuration parameters when starting job service. The example covers running PostgreSQL as a Kubernetes deployment but you can run it the way it fits in your environment, the important part is to set all the configuration parameters points to your running instance of PostgreSQL.
Job Service configuration

==== Ephemeral
Alternatively, there is an in-memory database implementation that does not require any external database configuration, similar to the workflow runtime embedded in-memory job service (link), it can be used for testing and development purposes, but it is not recommended for production, since all jobs are lost in case of a service restart or failure.

=== Job Service communication

[NOTE]
====
The Job Service does not execute a job but triggers a callback that might be an HTTP request or a Cloud Event that is managed by the configured jobs addon see(link addons config) in the workflow application.
====

==== Knative Eventing

You can configure job service to consume and publish events through knative setting some configuration parameters in your environment.
Addon configuration
The communication from the workflow application with Job Service is done through an addon which is responsible for publishing and consuming events related to timers. When running the workflow as a knative service, the kogito-addons-quarkus-jobs-knative-eventing should be added to the project as a dependency alongside the proper configuration.

Dependency:
.Callback state example with timeout
[source, xml]
----
<dependency>
    <groupId>org.kie.kogito</groupId>
    <artifactId>kogito-addons-quarkus-jobs-knative-eventing</artifactId>
</dependency>
----

Configuration parameters:

.Callback state example with timeout
[source, properties]
----
# Events produced by kogito-addons-quarkus-jobs-knative-eventing to program the timers on the job service.
mp.messaging.outgoing.kogito-job-service-job-request-events.connector=quarkus-http
mp.messaging.outgoing.kogito-job-service-job-request-events.url=${K_SINK:http://localhost:8280/jobs/events}
mp.messaging.outgoing.kogito-job-service-job-request-events.method=POST
----

[#timeout-example]
== Timeout showcase example

In the link:{kogito_sw_examples_url}/serverless-workflow-timeouts-showcase[serverless-workflow-timeouts-showcase] you can see a complete architecture, containing a serverless workflow application with timeouts configured alongside Job service running on Knative.

There are two workflows to showcase timeouts usage: `Callback` and `Switch` states.

=== Callback workflow

It is a simple workflow where once the execution reaches the callback state it waits for the event `callbackEvent`to be received and continue the execution.

.Callback timeout workflow
image::core/callback-state-timeouts.svg[]

.Callback event
[source, json]
----
{
"name": "callbackEvent",
"source": "",
"type": "callback_event_type"
}
----

A timeout is configured with a maximum time 30 seconds to be waited by the workflow to receive the callbackEvent, in case it does not arrive in time, the execution moves, and the eventData variable remains null.
See the <<callback-state, callback state definition>>.


=== Switch workflow

The switch example is similar to the callback but once the execution reaches the state, it waits for once of the two configured events, `visaDeniedEvent` or `visaApprovedEvent`, to be consumed, see the <<switch-state, switch state definition>>.

Whenever one of the events is consumed, before the configured timeout, the workflow execution moves to the next state defined in the `transition`.

If none of the events arrive before 30 seconds of timeout, the workflow then moves to the state defined in `defaultCondition' transition.

.Switch timeout workflow
image::core/switch-state-timeouts.svg[]

=== Running the example

In order to run the example you need to have a kubernetes or Openshift cluster running with Knative configured. In the example minikube is being used you can follow the steps described in the example's link:{kogito_sw_examples_url}/serverless-workflow-timeouts-showcase[readme].

All the descriptor files used to deploy the example infrastructure are present in the kubernetes folder, and for the workflow application, the descriptors are placed on the target/kubernetes, generated after the build.

The diagram below describes how is the architecture of the example to be deployed on kubernetes and Knative.

.Knative Workflow with Job service architecture
image::core/jobs-service-knative-architecture.png[]

==== Deploying the database

The workflow application and job service uses PostgreSQL as the persistence backend to store information about the workflow instances and jobs, respectively.
In the example you can deploy a single database instance to be used on both, in a production environment is recommended to have independent database instances.

To run PostgreSQL you need to apply the following on the cluster:

.Deploying the database
[source, shell]
----
kubectl apply -f kubernetes/timeouts-showcase-database.yml
----

.After executing the command, you will see an output like this:
[source, shell]
----
secret/timeouts-showcase-database created
deployment.apps/timeouts-showcase-database created
service/timeouts-showcase-database created
----

==== Deploying job Service
.Deploying Job Service
[source, shell]
----
kubectl apply -f kubernetes/jobs-service-postgresql.yml
----

.After executing the command, you will see an output like this:
[source, shell]
----
service/jobs-service-postgresql created
deployment.apps/jobs-service-postgresql created
trigger.eventing.knative.dev/jobs-service-postgresql-create-job-trigger created
trigger.eventing.knative.dev/jobs-service-postgresql-cancel-job-trigger created
sinkbinding.sources.knative.dev/jobs-service-postgresql-sb created
----

==== Deploying the timeout showcase workflow

You need to build the workflow with the `knative` maven profile, then the descriptor files are generated under the `target/kubernetes` folder, and the image is pushed in the container registry.

.Building the timeout workflow showcase for knative
[source, shell]
----
mvn clean install -Pknative
----

.Deploying the timeout workflow showcase in knative
[source, shell]
----
kubectl apply -f target/kubernetes/knative.yml
kubectl apply -f target/kubernetes/kogito.yml
----

.After executing the commands you will see an output like this:
[source, shell]
----
service.serving.knative.dev/timeouts-showcase created

trigger.eventing.knative.dev/visa-denied-event-type-trigger-timeouts-showcase created
trigger.eventing.knative.dev/visa-approved-event-type-trigger-timeouts-showcase created
trigger.eventing.knative.dev/callback-event-type-trigger-timeouts-showcase created
sinkbinding.sources.knative.dev/sb-timeouts-showcase created
----

==== Creating a workflow instance

To create a workflow you can interact with the workflow using the provided REST APIs, in the example provide a test Web UI to make it easy to test.

First, you need to get the service URL on the cluster.

.Getting the workflow service URL on the cluster
[source, shell]
----
kn service list | grep timeouts-showcase
----

.Service URL in the response, similar to this.
[source, shell]
----
NAME                      URL                                                             LATEST                          AGE     CONDITIONS   READY   REASON
timeouts-showcase         http://timeouts-showcase.default.10.105.86.217.sslip.io         timeouts-showcase-00001         3m50s   3 OK / 3     True
----

=== Using the show UI

The example Web UI is handy to interact with the workflow, you just need to open in the browser the URL you got from the previous step.

.Timeout workflow showcase UI
image::core/timeout-switch-wokflow-ui.png[]

You can create new workflow instances and interact with them to complete, or simply wait the timeout to be triggered to check it working.
More details on the link:{kogito_sw_examples_url}/serverless-workflow-timeouts-showcase#timeouts-showcase-ui[readme].

=== Using REST APIs

You can test the workflows using the REST APIs, in fact they are the same used by the Web UI in both workflows.

* Callback

.Creating a callback workflow with timeout
[source, shell]
----
curl -X 'POST' \
'http://timeouts-showcase.default.10.105.86.217.sslip.io/callback_state_timeouts' \
-H 'accept: */*' \
-H 'Content-Type: application/json' \
-d '{
"workflowdata": {}
}'
----

* Switch

.Creating a Switch workflow with timeout
[source, shell]
----
curl -X 'POST' \
'http://timeouts-showcase.default.10.105.86.217.sslip.io/callback_state_timeouts' \
-H 'accept: */*' \
-H 'Content-Type: application/json' \
-d '{
"workflowdata": {}
}'
----

* Checking whether the workflow instance was created

.Getting the created workflow instance
[source, shell]
----
curl -X 'GET' 'http://timeouts-showcase.default.10.105.86.217.sslip.io/switch_state_timeouts'
----

The command will produce an output like this, which indicates that the process is waiting for an event to arrive.

.Response with the created instance
[source, shell]
----
[{"id":"2e8e1930-9bae-4d60-b364-6fbd61128f51","workflowdata":{}}]
----

* Checking the timeout was executed after 30 seconds:

.Getting the created workflow instance after 30 seconds
[source, shell]
----
curl -X 'GET' 'http://timeouts-showcase.default.10.105.86.217.sslip.io/switch_state_timeouts'
[]
----

As you can see there are no active workflow instances, indicating the timout was executed and the created instance was completed.

== Additional resources

* xref:eventing/working-with-callbacks.adoc[Callback state in {context}]

include::../../pages/_common-content/report-issue.adoc[]