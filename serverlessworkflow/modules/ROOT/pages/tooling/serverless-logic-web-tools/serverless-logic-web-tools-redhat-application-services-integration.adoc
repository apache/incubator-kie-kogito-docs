= Red Hat OpenShift Application and Data Services integration
:compat-mode!:
// Metadata:
:description: {serverless_logic_web_tools_name} Red Hat OpenShift Application and Data Services integration
:keywords: kogito, workflow, serverless, editor, web, tools, settings, red hat, application, data, services, integration

Some {serverless_logic_web_tools_name} features require integration with Red Hat OpenShift Application and Data Services. Uploading OpenAPI specifications to a Service Registry and deploying {context} that required an Apache Kafka stream are some of the examples.

On this page, you'll configure all the settings needed for complete integration.

[[proc-setting-service-account-serverless-logic-web-tools]]
== Setting up a Service Account

Create or use a Service Account from your Red Hat OpenShift Application and Data Services console and add it to the {serverless_logic_web_tools_name} settings tab.

.Prerequisites
* Access to Red Hat OpenShift Application and Data Services console.

.Procedure
. Create a Service Account on Red Hat Openshift Application and Data Services console (if you already have one, skip this step):
  * Go to link:{openshift_application_data_services_service_account_url}[Service Accounts | Red Hat OpenShift Application and Data Services];
  * Click on **Create service account**;
  * In the window that opens up type a Service account name;
  * Click on **Create**.
  * A new modal will show up with your **Client ID** and **Client Secret**, copy those to somewhere safe and save it.
  * Check the **I have copied the client ID and secret** checkbox and click on **Close**.
. If you skipped the previous step, find your saved **Client ID** and **Client Secret** as they will be necessary for the next steps;
. In the {serverless_logic_web_tools_name}, click on the **Cog wheel** (⚙️) on the top right corner and go to the **Service Account** tab;
. Paste your **Client ID** and **Client Secret** in the respective fields;
. Click on **Apply**.
. The tab contents should be updated, showing **Your Service Account information is set**.


[[proc-setting-service-registry-serverless-logic-web-tools]]
== Setting up a Service Registry

Create or use a Service Registry instance from your Red Hat OpenShift Application and Data Services console and add it to the {serverless_logic_web_tools_name} settings tab.

.Prerequisites
* Access to Red Hat OpenShift Application and Data Services console;
* A Service Account.

.Procedure
. Create a Service Registry instance on Red Hat Openshift Application and Data Services console (if you already have one, skip this step):
  * Go to link:{openshift_application_data_services_service_registry_url}[Service Registry | Red Hat OpenShift Application and Data Services];
  * Click on **Create Service Registry instance**;
  * In the window that opens up type a Service Registry instance name;
  * Click on **Create**;
  * The list of instances will be updated with your new instance;
  * Find it in the list and click on its name;
  * Go to the **Settings** tab and click on **Grant access**;
  * From the dropdown, select your Service Account desired (the same you configured on the {serverless_logic_web_tools_name});
  * Select a role for that Service Account (has to be Manager or Administrator, to have read and write access);
  * Click on **Save**;
  * On the top right-hand corner there should be a triple dotted menu, click on it and then on **Connection**;
  * A drawer should open with all the connection and authentication information you'll need;
  * Copy the **Core Registry API** value.
. If you skipped the previous step, find your Service Registry instance **Core Registry API** as it will be necessary for the next steps;
. In the {serverless_logic_web_tools_name}, click on the **Cog wheel** (⚙️) on the top right corner and go to the **Service Registry** tab;
. Input a name for your registry, preferably the same one you used when creating the Service Registry instance;
. Paste your **Core Registry API** in the respective field;
. Click on **Apply**.
. The tab contents should be updated, showing **Your Service Registry information is set**.

[[proc-setting-apache-kafka-serverless-logic-web-tools]]
== Setting up Streams for Apache Kafka

Create or use a Kafka instance from your Red Hat OpenShift Application and Data Services console and add it to the {serverless_logic_web_tools_name} settings tab.

.Prerequisites
* Access to Red Hat OpenShift Application and Data Services console;

.Procedure
. Create a Kafka instance on Red Hat Openshift Application and Data Services console (if you already have one, skip this step):
  * Go to link:{openshift_application_data_services_apache_kafka_url}[Streams for Apache Kafka | Red Hat OpenShift Application and Data Services];
  * Click on **Create Kafka instance**;
  * In the window that opens up type a Kafka instance name;
  * Fill the other fields to your liking, or leave them with the default values;
  * Click on **Create instance**;
  * Reload the page for the list of instances to be updated with your new instance;
  * Wait for the status to be updated to **Ready**;
  * Find it in the list and click on its name;
  * Go to the **Topics** tab and create a new topic, you'll need its name later;
  * Go to the **Access** tab;
  * Click on **Manage Access** and select **All Accounts** or your Service Account;
  * Add the following permissions:
     ** _Consumer group is " * " | Allow All | All Accounts_;
     ** _Topic is " * " | Allow All | All Accounts_;
  * On the top right-hand corner there should be a triple dotted menu, click on it and then on **Connection**;
  * Copy the **Bootstrap server** value.
. If you skipped the previous step, find your Kafka instance **Bootstrap server** value as it will be necessary for the next steps;
. In the {serverless_logic_web_tools_name}, click on the **Cog wheel** (⚙️) on the top right corner and go to the **Streams for Apache Kafka** tab;
. Paste the **Bootstrap server** value you copied before to the **Bootstrap Server** field;
. Type the name of the topic you created on the **Topic** field;
. Click on **Apply**.
. The tab contents should be updated, showing **Your Streams for Apache Kafka information is set**.

Note: using these broad settings is meant to make it easy to configure but you can set up specific Service Accounts, Topics, and Consumer Groups as well.

include::../../../pages/_common-content/report-issue.adoc[]