= Consuming and producing events on Knative Eventing
:compat-mode!:
// Metadata:
:description: Consuming and producing events on Knative Eventing
:keywords: kogito, workflow, serverless, events, kafka
// links
:knative_eventing_doc_url: https://knative.dev/docs/eventing/

This document describes how you can configure Serverless Workflow to interact with link:{knative_eventing_doc_url}[Knative Eventing]. 

Knative Eventing abstracts the events consumption via the link:{knative_eventing_doc_url}/sources[Source] and link:{knative_eventing_doc_url}/sinks[Sink] components. An event source is the Kubernetes object that produces the event. The sink is the Kubernetes object that receives the event. The workflow application can act as a source, a sink or both in the Knative Eventing platform.

You need to add the Kogito Knative Eventing add-on dependency to indicate that you are using Knative Eventing. To enable Serverless Workflow to use Knative Eventing, add the following dependency to the `pom.xml` file of your project if using Maven:

.Add dependency for Kogito Knative Eventing add-on in `pom.xml`
[source,json]
----
<dependency>
    <groupId>org.kie.kogito</groupId>
    <artifactId>kogito-addons-quarkus-knative-eventing</artifactId>
</dependency>
----

This add-on will take care of the required dependencies and any additional configurations that the workflow application needs to connect to the Knative Eventing platform.

Although the default configuration that the Quarkus Knative Eventing add-on provides ought to be enough for the majority of uses cases, sometimes you may need to do additional configuration to serve a specific scenario. See the following sections for more information.

[[con-knative-eventing-add-on-source-configuration]]
== Knative Eventing add-on Source configuration

The following properties are only valid if the workflow has at least one [event definition] of the type `produced`. That's when the workflow application produces events, acting as a Knative Source.

See the sections below for more information of the configuration properties that you can define for your workflow application when it is an Event Source.

=== HTTP Transport Configuration

[Knative injects the `K_SINK` environment variable] in the workflow application when you deploy it in the cluster. Kogito uses this variable to address the produced events to the right Knative Sink. 

.HTTP Transport configuration
|===
|Property|Default|Description

|mp.messaging.outgoing.kogito_outgoing_stream.url
|${K_SINK:http://localhost:9090}
|Where to POST the HTTP CloudEvent message.

|mp.messaging.outgoing.kogito_outgoing_stream.connector
|`quarkus-http`
|Quarkus Smallrye channel implementation used by Kogito. It's unlikely that you need to change this property.

|===

=== Health Check Configuration

By default, the application will generate a [health check probe] to verify if the Knative platform injected the `K_SINK` variable and it's valid.

.Health Check Probe configuration
|===
|Property|Default|Description

|org.kie.kogito.addons.knative.health_enabled
|true
|Whether to enable the health check to verify if the `K_SINK` variable has been injected in the environment.

|===

=== Knative Target Sink Generation Configuration

Kogito Knative Eventing add-on generates a few Knative objects during build time. By default, it generates a [Knative Broker] named `default` if the workflow application is an Event Source.

.Knative Sink generation configuration
|===
|Property|Default|Description

|org.kie.kogito.addons.knative.auto_generate_broker
|true
|Whether the add-on should generate a default Knative Broker in memory to sink and dispatch the messages. Turn this property to `false` in case you already have a broker installed in your namespace rather than the default one. Note that you can use `org.kie.kogito.addons.knative.eventing.sink.*` to configure your custom Sink. If not defined, this auto generated Broker will work as the Sink.

|org.kie.kogito.addons.knative.sink.namespace
|
|Namespace where the generated Knative Sink is deployed.

|org.kie.kogito.addons.knative.sink.api_version
|eventing.knative.dev/v1
|Namespace where the generated Knative Sink is deployed.

|org.kie.kogito.addons.knative.sink.name
|`default`
|Name of the generated Knative Sink.

|org.kie.kogito.addons.knative.sink.kind
|Broker
|Kubernetes Kind of the generated Knative Sink.

|===

[[con-knative-eventing-add-on-sink-configuration]]
== Knative Eventing add-on Sink configuration

The following property is only valid if the workflow has at least one [event definition] of the type `consumed`. That's when the workflow application consume events, acting as a Knative Sink.

When the workflow application needs to consume events, the Knative Eventing add-on generates [Knative Triggers] configured specifically to listen from a [Broker] with the required [event type] as defined in your workflow definition.

.Knative Sink generation configuration
|===
|Property|Default|Description

|org.kie.kogito.addons.knative.broker
|`default`
|Name of the default Knative Broker deployed in the workflow application Kubernetes namespace. This broker is used as the reference to create the Knative Triggers responsible to delegate the events that this Kogito service will consume.

|===

[[con-generating-kn-objects-build-time]]
== Generating Knative Objects in Build Time

To generate the Knative Objects mentioned in the previous section, you must add the [Quarkus Kubernetes extension] to your project:

.Add dependency for Quarkus Kubernetes extension in `pom.xml`
[source,json]
----
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-kubernetes</artifactId>
</dependency>
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-container-image-jib</artifactId>
</dependency>
----

[TIP]
====
If you used the xref:[kn workflow CLI] to create your project, this extension is already present.
====

Add the property `quarkus.kubernetes.deployment-target=knative` to your `application.properties` file.

Having adding these dependencies to your project, when you build the workflow application, the `target/kubernetes` directory will contain two files: `knative.yml` and `kogito.yml`.

The `knative.yml` filehas the [Knative Service] representing the workflow application. The `kogito.yml` file has the required objects to plug the application to the Knative Eventing platform.

// TODO: add the image and an example of a workflow with the events definition
// TODO: add the links
// TODO: add a reference to the guide that explains how to deploy on minikube
// TODO: add the cards

== Additional resources

* xref:testing-and-troubleshooting/mocking-http-cloudevents-with-wiremock.adoc[Mocking HTTP CloudEvents sink using WireMock]
* xref:eventing/consume-producing-events-with-kafka.adoc[Consuming and producing events using Apache Kafka]
* xref:eventing/event-correlation-with-workflows.adoc[Event correlation in Serverless Workflow]
* xref:eventing/working-with-callbacks.adoc[Callback state in Serverless Workflow]

include::../../pages/_common-content/report-issue.adoc[]