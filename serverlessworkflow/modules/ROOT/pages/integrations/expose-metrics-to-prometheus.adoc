= Exposing workflow base metrics to Prometheus
:compat-mode!:
// Metadata:
:description: Exposing the workflow base metrics to Prometheus
:keywords: kogito, workflow, quarkus, metrics, prometheus
// links
:openshift_micrometer_url: https://quarkus.io/blog/micrometer-prometheus-openshift
:dashbuilder_url: https://www.dashbuilder.org/
:grafana_url: https://grafana.com/
:quarkus_micrometer_url: https://quarkus.io/guides/micrometer
:openshift_monitoring_url: https://docs.openshift.com/container-platform/4.11/monitoring/enabling-monitoring-for-user-defined-projects.html
:prometheus_operator_url: https://prometheus-operator.dev/
:prometheus_operator_getting_started_guide: https://prometheus.io/docs/prometheus/latest/getting_started/#configure-prometheus-to-monitor-the-sample-targets

{product_name} generates metrics that can be consumed by Prometheus and visualized by dashboard tools, such as link:{openshift_micrometer_url}[OpenShift], link:{dashbuilder_url}[Dashbuilder], and link:{grafana_url}[Grafana].

This document describes how you can enable and expose the generated metrics to Prometheus.

[[proc-enable-metrics-sw]]
== Enabling metrics in {product_name}

You can enable the metrics in your workflow application.

.Prerequisites
* A workflow application is created. 
+
For more information about creating a workflow, see xref:getting-started/create-your-first-workflow-service.adoc[Creating your first workflow service].

.Procedure
. To add the metrics to your workflow application, add the `org.kie.kogito:kogito-addons-quarkus-monitoring-prometheus` dependency to the `pom.xml` file of your project:
+
--
.Dependency to be added to the `pom.xml` file to enable metrics
[source,xml]
----
<dependency>
    <groupId>org.kie.kogito</groupId>
    <artifactId>kogito-addons-quarkus-monitoring-prometheus</artifactId>
</dependency>
----
--

. Rebuild your workflow application.
+
The metrics is available at `/q/metrics` endpoint.

[[con-consume-metrics-sw]]
== Metrics consumption in {product_name}

After enabling the metrics in {product_name}, the generated metrics can be consumed from OpenShift, Kubernetes, and Prometheus to visualize on different dashboard tools.

[[proc-consume-metrics-openshift]]
=== Consuming metrics from OpenShift

If your workflow server is running on OpenShift, then you can use the server to monitor your workflow application. Also, you can perform the task of consuming metrics from OpenShift.

.Prerequisites
* Metrics is enabled in {product_name}.
+
For more information, see <<proc-enable-metrics-sw, Enabling metrics in {product_name}>>.

.Procedure
. To consume metrics from OpenShift, enable monitoring for user-defined projects. 
+
--
For more information, see link:{openshift_monitoring_url}[Enabling monitoring for user-defined projects] in OpenShift documentation.

When you enable monitoring for user-defined projects, the Prometheus Operator is installed automatically. 
--

. Create a service monitor as shown in the following configuration:
+
--
.Example configuration in `service-monitor.yaml`
[source,yaml]
----
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    k8s-app: prometheus-app-monitor
  name: prometheus-app-monitor
  namespace: my-project
spec:
  endpoints:
  - interval: 30s
    targetPort: 8080
    path: /q/metrics
    scheme: http
  selector:
    matchLabels:
      app-with-metrics: 'serverless-workflow-app'
----
--

. Run the following command to apply the service monitor:
+
--
.Apply service monitor
[source,shell]
----
oc apply -f service-monitor.yaml
----
--

In the previous procedure, a service monitor named `prometheus-app-monitor` is created, which selects applications containing the label as `app-with-metrics: serverless-workflow-app`. Ensure that your workflow application contains the same label.

After that, Prometheus sends request to the `/q/metrics` endpoint for all the services that are labeled with `app-with-metrics: serverless-workflow-app` every 30 seconds. For more information about monitoring Quarkus application using Micrometer and Prometheus into OpenShift, see link:{openshift_micrometer_url}[Quarkus - Micrometer Metrics].

[IMPORTANT]
====
Consuming metrics from Kubernetes is similar to OpenShift. However, you need to install the Prometheus Operator project manually. 

For more information about installing Prometheus Operator, see link:{prometheus_operator_url}[Prometheus Operator] website.
====

[[proc-consume-metrics-prometheus]]
=== Consuming metrics from Prometheus

If your workflow server is running on Prometheus, then you can perform the task of consuming metrics from Prometheus and visualize the workflow on different dashboard tools.

.Prerequisites
* Metrics is enabled in {product_name}.
+
For more information, see <<proc-enable-metrics-sw, Enabling metrics in {product_name}>>.

.Procedure
. Use the following configuration to enable Prometheus to remove metrics directly from the workflow application:
+
--
.Example Prometheus configuration
[source,yaml]
----
- job_name: 'Serverless Workflow App'
    scrape_interval: 2s
    metrics_path: /q/metrics
    static_configs:
        - targets: ['localhost:8080']
----
--

. Replace the values of `job_name` and `scrap_interval` in the previous configuration with your own values.
. Ensure that `target` under `static_configs` parameter in Prometheus configuration matches with your workflow application location.
+
For more information about configuring Prometheus, see link:{prometheus_operator_getting_started_guide}[Configure Prometheus to monitor the sample targets] in Prometheus Getting Started document.

[[ref-sw-example-metrics]]
== Example metrics in {product_name}

In {product_name}, you can check the following example metrics:

* `kogito_process_instance_completed_total`: Completed workflows
* `kogito_process_instance_started_total`: Started workflows
* `kogito_process_instance_running_total`: Running workflows
* `kogito_process_instance_duration_seconds_sum`: Workflows total duration 

[NOTE]
====
Internally, workflows are referred as processes. Therefore, the `processId` and `processName` is workflow ID and name respectively.
====

Each of the metrics mentioned previously contains a label for a specific workflow ID. For example, the `kogito_process_instance_completed_total` metric contains labels for `jsongreet`, `yamlgreet`, and `foreach` workflows:

.Example `kogito_process_instance_completed_total` metric
[source,yaml]
----
# HELP kogito_process_instance_completed_total Completed Process Instances
# TYPE kogito_process_instance_completed_total counter
kogito_process_instance_completed_total{app_id="default-process-monitoring-listener",artifactId="kogito-serverless-workflow-demo",node_name="2",process_id="jsongreet",version="1.0.0-SNAPSHOT",} 154.0
kogito_process_instance_completed_total{app_id="default-process-monitoring-listener",artifactId="kogito-serverless-workflow-demo",node_name="2",process_id="yamlgreet",version="1.0.0-SNAPSHOT",} 218.0
kogito_process_instance_completed_total{app_id="default-process-monitoring-listener",artifactId="kogito-serverless-workflow-demo",node_name="2",process_id="foreach",version="1.0.0-SNAPSHOT",} 162.0
----

[NOTE]
====
Internally, {product_name} uses Quarkus Micrometer extension, which also exposes built-in metrics. You can disable the Micrometer metrics in {product_name}. For more information, see link:{quarkus_micrometer_url}[Quarkus - Micrometer Metrics].
====

include::../../pages/_common-content/report-issue.adoc[]